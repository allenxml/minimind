#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°† PyTorch .pth æ¨¡å‹è½¬æ¢ä¸º SafeTensors æ ¼å¼

SafeTensors æ ¼å¼ä¼˜åŠ¿ï¼š
- æ›´å®‰å…¨ï¼šçº¯æ•°æ®æ ¼å¼ï¼Œä¸ä¼šæ‰§è¡Œæ¶æ„ä»£ç 
- æ›´å¿«ï¼šåŠ è½½é€Ÿåº¦å¿«2-3å€
- è·¨æ¡†æ¶ï¼šæ”¯æŒ PyTorch/TensorFlow/JAX
- HuggingFaceå…¼å®¹ï¼šä¸HFç”Ÿæ€å®Œç¾é›†æˆ

ä½¿ç”¨æ–¹æ³•ï¼š
    python scripts/convert_to_safetensors.py out/pretrain_512.pth
    python scripts/convert_to_safetensors.py out/pretrain_512.pth --output models/pretrain_512.safetensors
"""

import os
import sys
import argparse
import torch
from pathlib import Path

try:
    from safetensors.torch import save_file, load_file
except ImportError:
    print("âŒ é”™è¯¯: safetensors æœªå®‰è£…")
    print("è¯·è¿è¡Œ: pip install safetensors")
    sys.exit(1)


def convert_pth_to_safetensors(pth_path, output_path=None, verify=True):
    """
    è½¬æ¢ .pth æ–‡ä»¶åˆ° .safetensors
    
    Args:
        pth_path: è¾“å…¥çš„.pthæ–‡ä»¶è·¯å¾„
        output_path: è¾“å‡ºçš„.safetensorsæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        verify: æ˜¯å¦éªŒè¯è½¬æ¢ç»“æœ
    
    Returns:
        str: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(pth_path):
        raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {pth_path}")
    
    # ç”Ÿæˆè¾“å‡ºè·¯å¾„
    if output_path is None:
        output_path = pth_path.replace('.pth', '.safetensors')
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(output_path) or '.', exist_ok=True)
    
    print(f"ğŸ”„ æ­£åœ¨åŠ è½½æ¨¡å‹: {pth_path}")
    
    try:
        # åŠ è½½PyTorchæ¨¡å‹
        state_dict = torch.load(pth_path, map_location='cpu')
        
        # å¦‚æœæ˜¯checkpointæ ¼å¼ï¼ˆåŒ…å«optimizerç­‰ï¼‰ï¼Œåªæå–modeléƒ¨åˆ†
        if isinstance(state_dict, dict):
            if 'model' in state_dict:
                print("   æ£€æµ‹åˆ°checkpointæ ¼å¼ï¼Œæå–modeléƒ¨åˆ†")
                state_dict = state_dict['model']
            elif 'state_dict' in state_dict:
                print("   æ£€æµ‹åˆ°checkpointæ ¼å¼ï¼Œæå–state_dictéƒ¨åˆ†")
                state_dict = state_dict['state_dict']
        
        # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
        total_params = sum(v.numel() for v in state_dict.values())
        print(f"   æ¨¡å‹å‚æ•°é‡: {total_params / 1e6:.2f}M")
        print(f"   å¼ é‡æ•°é‡: {len(state_dict)}")
        
        # è½¬æ¢æ‰€æœ‰tensorä¸ºè¿ç»­å­˜å‚¨ï¼ˆsafetensorsè¦æ±‚ï¼‰
        print("ğŸ”„ æ­£åœ¨è½¬æ¢ä¸ºè¿ç»­å­˜å‚¨æ ¼å¼...")
        state_dict = {k: v.contiguous() for k, v in state_dict.items()}
        
        print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜ä¸º SafeTensors æ ¼å¼: {output_path}")
        
        # ä¿å­˜ä¸ºsafetensors
        save_file(state_dict, output_path)
        
        # æ˜¾ç¤ºæ–‡ä»¶å¤§å°å¯¹æ¯”
        pth_size = os.path.getsize(pth_path) / (1024**2)
        safe_size = os.path.getsize(output_path) / (1024**2)
        
        print(f"\nâœ… è½¬æ¢å®Œæˆï¼")
        print(f"{'='*60}")
        print(f"   åŸå§‹ .pth å¤§å°:      {pth_size:.2f} MB")
        print(f"   è½¬æ¢å .safetensors: {safe_size:.2f} MB")
        print(f"   å¤§å°å·®å¼‚:           {safe_size - pth_size:+.2f} MB")
        print(f"{'='*60}")
        
        # éªŒè¯è½¬æ¢ç»“æœ
        if verify:
            print("\nğŸ” éªŒè¯è½¬æ¢ç»“æœ...")
            verify_conversion(pth_path, output_path, state_dict)
        
        return output_path
        
    except Exception as e:
        print(f"\nâŒ è½¬æ¢å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


def verify_conversion(pth_path, safetensors_path, original_state_dict=None):
    """
    éªŒè¯è½¬æ¢ç»“æœçš„æ­£ç¡®æ€§
    
    Args:
        pth_path: åŸå§‹.pthæ–‡ä»¶è·¯å¾„
        safetensors_path: è½¬æ¢åçš„.safetensorsæ–‡ä»¶è·¯å¾„
        original_state_dict: åŸå§‹state_dictï¼ˆå¯é€‰ï¼Œé¿å…é‡å¤åŠ è½½ï¼‰
    """
    try:
        # åŠ è½½safetensors
        safe_state_dict = load_file(safetensors_path)
        
        # å¦‚æœæ²¡æœ‰æä¾›åŸå§‹state_dictï¼ŒåŠ è½½å®ƒ
        if original_state_dict is None:
            original_state_dict = torch.load(pth_path, map_location='cpu')
            if isinstance(original_state_dict, dict):
                if 'model' in original_state_dict:
                    original_state_dict = original_state_dict['model']
                elif 'state_dict' in original_state_dict:
                    original_state_dict = original_state_dict['state_dict']
        
        # æ£€æŸ¥é”®æ˜¯å¦ä¸€è‡´
        orig_keys = set(original_state_dict.keys())
        safe_keys = set(safe_state_dict.keys())
        
        if orig_keys != safe_keys:
            print("   âš ï¸  è­¦å‘Š: é”®ä¸å®Œå…¨åŒ¹é…")
            missing = orig_keys - safe_keys
            extra = safe_keys - orig_keys
            if missing:
                print(f"      ç¼ºå¤±çš„é”®: {missing}")
            if extra:
                print(f"      é¢å¤–çš„é”®: {extra}")
        else:
            print("   âœ… é”®åŒ¹é…: æ‰€æœ‰é”®éƒ½æ­£ç¡®")
        
        # æ£€æŸ¥å¼ é‡å€¼æ˜¯å¦ä¸€è‡´ï¼ˆæŠ½æ ·æ£€æŸ¥ï¼‰
        mismatches = 0
        for key in list(orig_keys)[:5]:  # æ£€æŸ¥å‰5ä¸ªå¼ é‡
            if key in safe_keys:
                orig_tensor = original_state_dict[key]
                safe_tensor = safe_state_dict[key]
                
                if not torch.allclose(orig_tensor, safe_tensor, rtol=1e-5, atol=1e-6):
                    mismatches += 1
                    print(f"   âš ï¸  å¼ é‡å€¼ä¸åŒ¹é…: {key}")
        
        if mismatches == 0:
            print("   âœ… å¼ é‡å€¼éªŒè¯: é€šè¿‡ï¼ˆæŠ½æ ·æ£€æŸ¥ï¼‰")
        else:
            print(f"   âš ï¸  å‘ç° {mismatches} ä¸ªå¼ é‡å€¼ä¸åŒ¹é…")
        
        print("\nâœ… éªŒè¯å®Œæˆï¼šè½¬æ¢æˆåŠŸï¼")
        
    except Exception as e:
        print(f"   âš ï¸  éªŒè¯è¿‡ç¨‹å‡ºé”™: {e}")


def batch_convert(input_dir, output_dir=None, pattern="*.pth"):
    """
    æ‰¹é‡è½¬æ¢ç›®å½•ä¸‹çš„æ‰€æœ‰.pthæ–‡ä»¶
    
    Args:
        input_dir: è¾“å…¥ç›®å½•
        output_dir: è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸ºè¾“å…¥ç›®å½•ï¼‰
        pattern: æ–‡ä»¶åŒ¹é…æ¨¡å¼
    """
    input_path = Path(input_dir)
    if not input_path.exists():
        raise FileNotFoundError(f"è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
    
    # æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…çš„æ–‡ä»¶
    pth_files = list(input_path.glob(pattern))
    
    if not pth_files:
        print(f"âŒ åœ¨ {input_dir} ä¸­æœªæ‰¾åˆ°åŒ¹é… {pattern} çš„æ–‡ä»¶")
        return
    
    print(f"ğŸ” æ‰¾åˆ° {len(pth_files)} ä¸ªæ–‡ä»¶å¾…è½¬æ¢")
    print(f"{'='*60}\n")
    
    success_count = 0
    for i, pth_file in enumerate(pth_files, 1):
        print(f"[{i}/{len(pth_files)}] è½¬æ¢: {pth_file.name}")
        
        try:
            # ç”Ÿæˆè¾“å‡ºè·¯å¾„
            if output_dir:
                output_path = Path(output_dir) / pth_file.name.replace('.pth', '.safetensors')
            else:
                output_path = pth_file.with_suffix('.safetensors')
            
            convert_pth_to_safetensors(str(pth_file), str(output_path), verify=False)
            success_count += 1
            print()
            
        except Exception as e:
            print(f"âŒ è½¬æ¢å¤±è´¥: {e}\n")
            continue
    
    print(f"{'='*60}")
    print(f"âœ… æ‰¹é‡è½¬æ¢å®Œæˆ: {success_count}/{len(pth_files)} ä¸ªæ–‡ä»¶æˆåŠŸ")
    print(f"{'='*60}")


def main():
    parser = argparse.ArgumentParser(
        description="è½¬æ¢PyTorchæ¨¡å‹ä¸ºSafeTensorsæ ¼å¼",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # è½¬æ¢å•ä¸ªæ–‡ä»¶
  python scripts/convert_to_safetensors.py out/pretrain_512.pth
  
  # æŒ‡å®šè¾“å‡ºè·¯å¾„
  python scripts/convert_to_safetensors.py out/pretrain_512.pth --output models/pretrain_512.safetensors
  
  # æ‰¹é‡è½¬æ¢
  python scripts/convert_to_safetensors.py --batch out/
  
  # æ‰¹é‡è½¬æ¢åˆ°æŒ‡å®šç›®å½•
  python scripts/convert_to_safetensors.py --batch out/ --output models/
  
  # è·³è¿‡éªŒè¯ï¼ˆæ›´å¿«ï¼‰
  python scripts/convert_to_safetensors.py out/pretrain_512.pth --no-verify
        """
    )
    
    parser.add_argument("input", type=str, help="è¾“å…¥çš„.pthæ–‡ä»¶è·¯å¾„æˆ–ç›®å½•ï¼ˆé…åˆ--batchï¼‰")
    parser.add_argument("--output", type=str, default=None, help="è¾“å‡ºçš„.safetensorsæ–‡ä»¶è·¯å¾„æˆ–ç›®å½•")
    parser.add_argument("--batch", action="store_true", help="æ‰¹é‡è½¬æ¢æ¨¡å¼")
    parser.add_argument("--pattern", type=str, default="*.pth", help="æ‰¹é‡è½¬æ¢æ—¶çš„æ–‡ä»¶åŒ¹é…æ¨¡å¼ï¼ˆé»˜è®¤: *.pthï¼‰")
    parser.add_argument("--no-verify", action="store_true", help="è·³è¿‡è½¬æ¢éªŒè¯ï¼ˆåŠ å¿«é€Ÿåº¦ï¼‰")
    
    args = parser.parse_args()
    
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘         PyTorch to SafeTensors è½¬æ¢å·¥å…·                   â•‘
â•‘         MiniMind Project                                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")
    
    try:
        if args.batch:
            # æ‰¹é‡è½¬æ¢æ¨¡å¼
            batch_convert(args.input, args.output, args.pattern)
        else:
            # å•æ–‡ä»¶è½¬æ¢æ¨¡å¼
            convert_pth_to_safetensors(args.input, args.output, verify=not args.no_verify)
        
        print("\nğŸ‰ æ‰€æœ‰æ“ä½œå®Œæˆï¼")
        
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()

