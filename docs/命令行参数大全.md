# å‘½ä»¤è¡Œå‚æ•°å¤§å…¨ï¼ˆå®Œæ•´ç‰ˆï¼‰

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜ MiniMind æ‰€æœ‰è„šæœ¬çš„å‘½ä»¤è¡Œå‚æ•°ï¼Œå¹¶æä¾›å®ç”¨çš„å‘½ä»¤ç¤ºä¾‹ã€‚

---

## ğŸ“‹ ç›®å½•

**è®­ç»ƒè„šæœ¬**:
1. [é¢„è®­ç»ƒè„šæœ¬å‚æ•°](#1-é¢„è®­ç»ƒè„šæœ¬å‚æ•°)
2. [ç›‘ç£å¾®è°ƒè„šæœ¬å‚æ•°](#2-ç›‘ç£å¾®è°ƒè„šæœ¬å‚æ•°)
3. [LoRA å¾®è°ƒè„šæœ¬å‚æ•°](#3-lora-å¾®è°ƒè„šæœ¬å‚æ•°)
4. [DPO è®­ç»ƒè„šæœ¬å‚æ•°](#4-dpo-è®­ç»ƒè„šæœ¬å‚æ•°)
5. [æ¨ç†è’¸é¦è„šæœ¬å‚æ•°](#5-æ¨ç†è’¸é¦è„šæœ¬å‚æ•°)
6. [çŸ¥è¯†è’¸é¦è„šæœ¬å‚æ•°](#6-çŸ¥è¯†è’¸é¦è„šæœ¬å‚æ•°)
7. [PPO è®­ç»ƒè„šæœ¬å‚æ•°](#7-ppo-è®­ç»ƒè„šæœ¬å‚æ•°)
8. [GRPO è®­ç»ƒè„šæœ¬å‚æ•°](#8-grpo-è®­ç»ƒè„šæœ¬å‚æ•°)
9. [SPO è®­ç»ƒè„šæœ¬å‚æ•°](#9-spo-è®­ç»ƒè„šæœ¬å‚æ•°)
10. [API åœ¨çº¿è’¸é¦è®­ç»ƒå‚æ•°](#10-api-åœ¨çº¿è’¸é¦è®­ç»ƒå‚æ•°)

**æ•°æ®ç”Ÿæˆè„šæœ¬**:
11. [API è’¸é¦æ•°æ®ç”Ÿæˆå‚æ•°](#11-api-è’¸é¦æ•°æ®ç”Ÿæˆå‚æ•°)
12. [API é—®ç­”å¯¹ç”Ÿæˆå‚æ•°](#12-api-é—®ç­”å¯¹ç”Ÿæˆå‚æ•°)

**æ¨ç†è„šæœ¬**:
13. [æ¨ç†è„šæœ¬å‚æ•°](#13-æ¨ç†è„šæœ¬å‚æ•°)

---

## 1. é¢„è®­ç»ƒè„šæœ¬å‚æ•°

**è„šæœ¬**: `trainer/train_pretrain.py`

### å‚æ•°è¡¨

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| **ä¿å­˜ç›¸å…³** |
| `--save_dir` | str | `../out` | æ¨¡å‹æƒé‡ä¿å­˜ç›®å½• |
| `--save_weight` | str | `pretrain` | ä¿å­˜æƒé‡çš„å‰ç¼€å |
| **è®­ç»ƒè¶…å‚æ•°** |
| `--epochs` | int | `1` | è®­ç»ƒè½®æ•°ã€‚é¢„è®­ç»ƒå»ºè®® 1-2 è½® |
| `--batch_size` | int | `32` | æ¯ä¸ª GPU çš„æ‰¹æ¬¡å¤§å° |
| `--learning_rate` | float | `5e-4` | åˆå§‹å­¦ä¹ ç‡ |
| `--device` | str | `cuda:0` | è®­ç»ƒè®¾å¤‡ |
| `--dtype` | str | `bfloat16` | æ··åˆç²¾åº¦ç±»å‹ |
| `--num_workers` | int | `1` | æ•°æ®åŠ è½½çº¿ç¨‹æ•° |
| `--accumulation_steps` | int | `8` | æ¢¯åº¦ç´¯ç§¯æ­¥æ•° |
| `--grad_clip` | float | `1.0` | æ¢¯åº¦è£å‰ªé˜ˆå€¼ |
| `--log_interval` | int | `100` | æ—¥å¿—æ‰“å°é—´éš”ï¼ˆæ­¥æ•°ï¼‰ |
| `--save_interval` | int | `100` | æ¨¡å‹ä¿å­˜é—´éš”ï¼ˆæ­¥æ•°ï¼‰ |
| **æ¨¡å‹æ¶æ„** |
| `--hidden_size` | int | `512` | éšè—å±‚ç»´åº¦ |
| `--num_hidden_layers` | int | `8` | Transformer å±‚æ•° |
| `--max_seq_len` | int | `512` | æœ€å¤§åºåˆ—é•¿åº¦ |
| `--use_moe` | int | `0` | æ˜¯å¦ä½¿ç”¨ MoE (0/1) |
| **æ•°æ®å’Œæƒé‡** |
| `--data_path` | str | `../dataset/pretrain_hq.jsonl` | é¢„è®­ç»ƒæ•°æ®è·¯å¾„ |
| `--from_weight` | str | `none` | åŸºäºå“ªä¸ªæƒé‡è®­ç»ƒ |
| `--from_resume` | int | `0` | æ˜¯å¦ç»­è®­ (0/1) |
| **æ—¥å¿—** |
| `--use_wandb` | flag | `False` | æ˜¯å¦ä½¿ç”¨ wandb |
| `--wandb_project` | str | `MiniMind-Pretrain` | wandb é¡¹ç›®å |

### ğŸ’¡ å®ç”¨å‘½ä»¤ç¤ºä¾‹

#### åŸºç¡€é¢„è®­ç»ƒï¼ˆSmall æ¨¡å‹ï¼‰
```bash
python trainer/train_pretrain.py \
    --epochs 1 \
    --batch_size 32 \
    --learning_rate 5e-4 \
    --hidden_size 512 \
    --num_hidden_layers 8 \
    --max_seq_len 512 \
    --data_path ./dataset/pretrain_hq.jsonl \
    --save_weight pretrain
```

#### é¢„è®­ç»ƒ Base æ¨¡å‹ï¼ˆæ›´å¤§æ¨¡å‹ï¼‰
```bash
python trainer/train_pretrain.py \
    --epochs 1 \
    --batch_size 16 \
    --learning_rate 3e-4 \
    --hidden_size 768 \
    --num_hidden_layers 16 \
    --max_seq_len 512 \
    --accumulation_steps 16 \
    --data_path ./dataset/pretrain_hq.jsonl \
    --save_weight pretrain
```

#### é¢„è®­ç»ƒ MoE æ¨¡å‹
```bash
python trainer/train_pretrain.py \
    --epochs 1 \
    --batch_size 24 \
    --learning_rate 5e-4 \
    --hidden_size 640 \
    --num_hidden_layers 8 \
    --use_moe 1 \
    --max_seq_len 512 \
    --data_path ./dataset/pretrain_hq.jsonl \
    --save_weight pretrain
```

#### å¤šå¡å¹¶è¡Œè®­ç»ƒï¼ˆDDPï¼‰
```bash
torchrun --nproc_per_node 4 trainer/train_pretrain.py \
    --epochs 1 \
    --batch_size 32 \
    --learning_rate 5e-4 \
    --hidden_size 512 \
    --num_hidden_layers 8 \
    --accumulation_steps 2 \
    --use_wandb \
    --wandb_project MiniMind-Pretrain
```

#### æ–­ç‚¹ç»­è®­
```bash
python trainer/train_pretrain.py \
    --from_resume 1 \
    --epochs 1 \
    --batch_size 32 \
    --learning_rate 5e-4
```

---

## 2. ç›‘ç£å¾®è°ƒè„šæœ¬å‚æ•°

**è„šæœ¬**: `trainer/train_full_sft.py`

### å‚æ•°è¡¨

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| **ä¿å­˜ç›¸å…³** |
| `--save_dir` | str | `../out` | æ¨¡å‹ä¿å­˜ç›®å½• |
| `--save_weight` | str | `full_sft` | ä¿å­˜æƒé‡å‰ç¼€ |
| **è®­ç»ƒè¶…å‚æ•°** |
| `--epochs` | int | `2` | è®­ç»ƒè½®æ•° |
| `--batch_size` | int | `16` | æ‰¹æ¬¡å¤§å° |
| `--learning_rate` | float | `5e-7` | å­¦ä¹ ç‡ï¼ˆâš ï¸ æ¯”é¢„è®­ç»ƒå°100-1000å€ï¼‰ |
| `--device` | str | `cuda:0` | è®­ç»ƒè®¾å¤‡ |
| `--dtype` | str | `bfloat16` | æ··åˆç²¾åº¦ç±»å‹ |
| `--num_workers` | int | `1` | æ•°æ®åŠ è½½çº¿ç¨‹æ•° |
| `--accumulation_steps` | int | `1` | æ¢¯åº¦ç´¯ç§¯æ­¥æ•° |
| `--grad_clip` | float | `1.0` | æ¢¯åº¦è£å‰ªé˜ˆå€¼ |
| `--log_interval` | int | `100` | æ—¥å¿—æ‰“å°é—´éš” |
| `--save_interval` | int | `100` | ä¿å­˜é—´éš” |
| **æ¨¡å‹æ¶æ„** |
| `--hidden_size` | int | `512` | éšè—å±‚ç»´åº¦ |
| `--num_hidden_layers` | int | `8` | Transformer å±‚æ•° |
| `--max_seq_len` | int | `512` | æœ€å¤§åºåˆ—é•¿åº¦ |
| `--use_moe` | int | `0` | æ˜¯å¦ä½¿ç”¨ MoE |
| **æ•°æ®å’Œæƒé‡** |
| `--data_path` | str | `../dataset/sft_mini_512.jsonl` | SFT æ•°æ®è·¯å¾„ |
| `--from_weight` | str | `pretrain` | åŸºäºå“ªä¸ªæƒé‡è®­ç»ƒ |
| `--from_resume` | int | `0` | æ˜¯å¦ç»­è®­ |
| **æ—¥å¿—** |
| `--use_wandb` | flag | `False` | æ˜¯å¦ä½¿ç”¨ wandb |
| `--wandb_project` | str | `MiniMind-Full-SFT` | wandb é¡¹ç›®å |

### ğŸ’¡ å®ç”¨å‘½ä»¤ç¤ºä¾‹

#### åŸºç¡€ SFTï¼ˆåŸºäºé¢„è®­ç»ƒæ¨¡å‹ï¼‰
```bash
python trainer/train_full_sft.py \
    --epochs 2 \
    --batch_size 16 \
    --learning_rate 5e-7 \
    --hidden_size 512 \
    --num_hidden_layers 8 \
    --max_seq_len 512 \
    --data_path ./dataset/sft_mini_512.jsonl \
    --from_weight pretrain \
    --save_weight full_sft
```

#### é•¿æ–‡æœ¬ SFTï¼ˆ1024 é•¿åº¦ï¼‰
```bash
python trainer/train_full_sft.py \
    --epochs 2 \
    --batch_size 8 \
    --learning_rate 3e-7 \
    --hidden_size 512 \
    --num_hidden_layers 8 \
    --max_seq_len 1024 \
    --data_path ./dataset/sft_1024.jsonl \
    --from_weight pretrain \
    --save_weight full_sft_1024
```

#### æé•¿æ–‡æœ¬ SFTï¼ˆ2048 é•¿åº¦ï¼‰
```bash
python trainer/train_full_sft.py \
    --epochs 1 \
    --batch_size 4 \
    --learning_rate 1e-7 \
    --hidden_size 512 \
    --num_hidden_layers 8 \
    --max_seq_len 2048 \
    --accumulation_steps 4 \
    --data_path ./dataset/sft_2048.jsonl \
    --from_weight pretrain \
    --save_weight full_sft_2048
```

#### Base æ¨¡å‹ SFT
```bash
python trainer/train_full_sft.py \
    --epochs 2 \
    --batch_size 8 \
    --learning_rate 3e-7 \
    --hidden_size 768 \
    --num_hidden_layers 16 \
    --max_seq_len 512 \
    --accumulation_steps 2 \
    --data_path ./dataset/sft_mini_512.jsonl \
    --from_weight pretrain \
    --save_weight full_sft
```

---

## 3. LoRA å¾®è°ƒè„šæœ¬å‚æ•°

**è„šæœ¬**: `trainer/train_lora.py`

### å‚æ•°è¡¨

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| **ä¿å­˜ç›¸å…³** |
| `--save_dir` | str | `../out/lora` | LoRA æƒé‡ä¿å­˜ç›®å½• |
| `--lora_name` | str | `lora_identity` | LoRA æƒé‡åç§° |
| **è®­ç»ƒè¶…å‚æ•°** |
| `--epochs` | int | `50` | è®­ç»ƒè½®æ•° |
| `--batch_size` | int | `32` | æ‰¹æ¬¡å¤§å° |
| `--learning_rate` | float | `1e-4` | å­¦ä¹ ç‡ï¼ˆLoRA å¯ç”¨è¾ƒå¤§å­¦ä¹ ç‡ï¼‰ |
| `--device` | str | `cuda:0` | è®­ç»ƒè®¾å¤‡ |
| `--dtype` | str | `bfloat16` | æ··åˆç²¾åº¦ç±»å‹ |
| `--num_workers` | int | `1` | æ•°æ®åŠ è½½çº¿ç¨‹æ•° |
| `--accumulation_steps` | int | `1` | æ¢¯åº¦ç´¯ç§¯æ­¥æ•° |
| `--grad_clip` | float | `1.0` | æ¢¯åº¦è£å‰ªé˜ˆå€¼ |
| `--log_interval` | int | `10` | æ—¥å¿—æ‰“å°é—´éš” |
| `--save_interval` | int | `1` | ä¿å­˜é—´éš”ï¼ˆæ¯ epochï¼‰ |
| **æ¨¡å‹æ¶æ„** |
| `--hidden_size` | int | `512` | éšè—å±‚ç»´åº¦ |
| `--num_hidden_layers` | int | `8` | Transformer å±‚æ•° |
| `--max_seq_len` | int | `512` | æœ€å¤§åºåˆ—é•¿åº¦ |
| `--use_moe` | int | `0` | æ˜¯å¦ä½¿ç”¨ MoE |
| **æ•°æ®å’Œæƒé‡** |
| `--data_path` | str | `../dataset/lora_identity.jsonl` | LoRA æ•°æ®è·¯å¾„ |
| `--from_weight` | str | `full_sft` | åŸºäºå“ªä¸ªæƒé‡ |
| `--from_resume` | int | `0` | æ˜¯å¦ç»­è®­ |
| **æ—¥å¿—** |
| `--use_wandb` | flag | `False` | æ˜¯å¦ä½¿ç”¨ wandb |
| `--wandb_project` | str | `MiniMind-LoRA` | wandb é¡¹ç›®å |

### ğŸ’¡ å®ç”¨å‘½ä»¤ç¤ºä¾‹

#### èº«ä»½è®¤çŸ¥ LoRA å¾®è°ƒ
```bash
python trainer/train_lora.py \
    --epochs 50 \
    --batch_size 32 \
    --learning_rate 1e-4 \
    --hidden_size 512 \
    --num_hidden_layers 8 \
    --data_path ./dataset/lora_identity.jsonl \
    --from_weight full_sft \
    --lora_name lora_identity
```

#### åŒ»ç–—é¢†åŸŸ LoRA å¾®è°ƒ
```bash
python trainer/train_lora.py \
    --epochs 50 \
    --batch_size 16 \
    --learning_rate 5e-5 \
    --hidden_size 512 \
    --num_hidden_layers 8 \
    --data_path ./dataset/lora_medical.jsonl \
    --from_weight dpo \
    --lora_name lora_medical
```

#### åŸºäº DPO æ¨¡å‹çš„ LoRA
```bash
python trainer/train_lora.py \
    --epochs 30 \
    --batch_size 32 \
    --learning_rate 1e-4 \
    --hidden_size 512 \
    --num_hidden_layers 8 \
    --data_path ./dataset/lora_custom.jsonl \
    --from_weight dpo \
    --lora_name lora_custom
```

---

## 4. DPO è®­ç»ƒè„šæœ¬å‚æ•°

**è„šæœ¬**: `trainer/train_dpo.py`

### å‚æ•°è¡¨

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| **ä¿å­˜ç›¸å…³** |
| `--save_dir` | str | `../out` | æ¨¡å‹ä¿å­˜ç›®å½• |
| `--save_weight` | str | `dpo` | ä¿å­˜æƒé‡å‰ç¼€ |
| **è®­ç»ƒè¶…å‚æ•°** |
| `--epochs` | int | `1` | è®­ç»ƒè½®æ•° |
| `--batch_size` | int | `4` | æ‰¹æ¬¡å¤§å°ï¼ˆâš ï¸ DPO éœ€è¦è¾ƒå° batchï¼‰ |
| `--learning_rate` | float | `4e-8` | å­¦ä¹ ç‡ï¼ˆâš ï¸ DPO éœ€è¦æå°å­¦ä¹ ç‡ï¼‰ |
| `--device` | str | `cuda:0` | è®­ç»ƒè®¾å¤‡ |
| `--dtype` | str | `bfloat16` | æ··åˆç²¾åº¦ç±»å‹ |
| `--num_workers` | int | `1` | æ•°æ®åŠ è½½çº¿ç¨‹æ•° |
| `--accumulation_steps` | int | `1` | æ¢¯åº¦ç´¯ç§¯æ­¥æ•° |
| `--grad_clip` | float | `1.0` | æ¢¯åº¦è£å‰ªé˜ˆå€¼ |
| `--log_interval` | int | `100` | æ—¥å¿—æ‰“å°é—´éš” |
| `--save_interval` | int | `100` | ä¿å­˜é—´éš” |
| **æ¨¡å‹æ¶æ„** |
| `--hidden_size` | int | `512` | éšè—å±‚ç»´åº¦ |
| `--num_hidden_layers` | int | `8` | Transformer å±‚æ•° |
| `--max_seq_len` | int | `1024` | æœ€å¤§åºåˆ—é•¿åº¦ |
| `--use_moe` | int | `0` | æ˜¯å¦ä½¿ç”¨ MoE |
| **æ•°æ®å’Œæƒé‡** |
| `--data_path` | str | `../dataset/dpo.jsonl` | DPO æ•°æ®è·¯å¾„ |
| `--from_weight` | str | `full_sft` | åŸºäºå“ªä¸ªæƒé‡ |
| `--from_resume` | int | `0` | æ˜¯å¦ç»­è®­ |
| **DPO ç‰¹å®šå‚æ•°** |
| `--beta` | float | `0.1` | DPO æ¸©åº¦å‚æ•° |
| **æ—¥å¿—** |
| `--use_wandb` | flag | `False` | æ˜¯å¦ä½¿ç”¨ wandb |
| `--wandb_project` | str | `MiniMind-DPO` | wandb é¡¹ç›®å |

### ğŸ’¡ å®ç”¨å‘½ä»¤ç¤ºä¾‹

#### åŸºç¡€ DPO è®­ç»ƒ
```bash
python trainer/train_dpo.py \
    --epochs 1 \
    --batch_size 4 \
    --learning_rate 4e-8 \
    --hidden_size 512 \
    --num_hidden_layers 8 \
    --max_seq_len 1024 \
    --data_path ./dataset/dpo.jsonl \
    --from_weight full_sft \
    --beta 0.1 \
    --save_weight dpo
```

#### æ›´å¤§ beta çš„ DPOï¼ˆæ›´æ¿€è¿›çš„åå¥½å­¦ä¹ ï¼‰
```bash
python trainer/train_dpo.py \
    --epochs 1 \
    --batch_size 4 \
    --learning_rate 3e-8 \
    --hidden_size 512 \
    --num_hidden_layers 8 \
    --max_seq_len 1024 \
    --data_path ./dataset/dpo.jsonl \
    --from_weight full_sft \
    --beta 0.2 \
    --save_weight dpo_beta02
```

#### Base æ¨¡å‹ DPO
```bash
python trainer/train_dpo.py \
    --epochs 1 \
    --batch_size 2 \
    --learning_rate 2e-8 \
    --hidden_size 768 \
    --num_hidden_layers 16 \
    --max_seq_len 1024 \
    --accumulation_steps 2 \
    --data_path ./dataset/dpo.jsonl \
    --from_weight full_sft \
    --beta 0.1 \
    --save_weight dpo
```

---

## 5. æ¨ç†è’¸é¦è„šæœ¬å‚æ•°

**è„šæœ¬**: `trainer/train_distill_reason.py`

### å‚æ•°è¡¨

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| **ä¿å­˜ç›¸å…³** |
| `--save_dir` | str | `../out` | æ¨¡å‹ä¿å­˜ç›®å½• |
| `--save_weight` | str | `reason` | ä¿å­˜æƒé‡å‰ç¼€ |
| **è®­ç»ƒè¶…å‚æ•°** |
| `--epochs` | int | `1` | è®­ç»ƒè½®æ•° |
| `--batch_size` | int | `8` | æ‰¹æ¬¡å¤§å° |
| `--learning_rate` | float | `1e-6` | å­¦ä¹ ç‡ |
| `--device` | str | `cuda:0` | è®­ç»ƒè®¾å¤‡ |
| `--dtype` | str | `bfloat16` | æ··åˆç²¾åº¦ç±»å‹ |
| `--num_workers` | int | `1` | æ•°æ®åŠ è½½çº¿ç¨‹æ•° |
| `--accumulation_steps` | int | `1` | æ¢¯åº¦ç´¯ç§¯æ­¥æ•° |
| `--grad_clip` | float | `1.0` | æ¢¯åº¦è£å‰ªé˜ˆå€¼ |
| `--log_interval` | int | `100` | æ—¥å¿—æ‰“å°é—´éš” |
| `--save_interval` | int | `100` | ä¿å­˜é—´éš” |
| **æ¨¡å‹æ¶æ„** |
| `--hidden_size` | int | `512` | éšè—å±‚ç»´åº¦ |
| `--num_hidden_layers` | int | `8` | Transformer å±‚æ•° |
| `--max_seq_len` | int | `1024` | æœ€å¤§åºåˆ—é•¿åº¦ |
| `--use_moe` | int | `0` | æ˜¯å¦ä½¿ç”¨ MoE |
| **æ•°æ®å’Œæƒé‡** |
| `--data_path` | str | `../dataset/r1_mix_1024.jsonl` | æ¨ç†è’¸é¦æ•°æ® |
| `--from_weight` | str | `dpo` | åŸºäºå“ªä¸ªæƒé‡ï¼ˆæ¨è DPOï¼‰ |
| `--from_resume` | int | `0` | æ˜¯å¦ç»­è®­ |
| **æ—¥å¿—** |
| `--use_wandb` | flag | `False` | æ˜¯å¦ä½¿ç”¨ wandb |
| `--wandb_project` | str | `MiniMind-Reasoning` | wandb é¡¹ç›®å |

### ğŸ’¡ å®ç”¨å‘½ä»¤ç¤ºä¾‹

#### åŸºç¡€æ¨ç†è’¸é¦ï¼ˆä» DeepSeek-R1 æ•°æ®ï¼‰
```bash
python trainer/train_distill_reason.py \
    --epochs 1 \
    --batch_size 8 \
    --learning_rate 1e-6 \
    --hidden_size 512 \
    --num_hidden_layers 8 \
    --max_seq_len 1024 \
    --data_path ./dataset/r1_mix_1024.jsonl \
    --from_weight dpo \
    --save_weight reason
```

#### ä» API ç”Ÿæˆçš„æ¨ç†æ•°æ®è®­ç»ƒ
```bash
python trainer/train_distill_reason.py \
    --epochs 1 \
    --batch_size 8 \
    --learning_rate 1e-6 \
    --hidden_size 512 \
    --num_hidden_layers 8 \
    --max_seq_len 1024 \
    --data_path ./dataset/distill_opus45_reasoning.jsonl \
    --from_weight dpo \
    --save_weight reason_opus45
```

#### Base æ¨¡å‹æ¨ç†è’¸é¦
```bash
python trainer/train_distill_reason.py \
    --epochs 1 \
    --batch_size 4 \
    --learning_rate 5e-7 \
    --hidden_size 768 \
    --num_hidden_layers 16 \
    --max_seq_len 1024 \
    --accumulation_steps 2 \
    --data_path ./dataset/r1_mix_1024.jsonl \
    --from_weight dpo \
    --save_weight reason
```

---

## 6. çŸ¥è¯†è’¸é¦è„šæœ¬å‚æ•°

**è„šæœ¬**: `trainer/train_distillation.py`

### å‚æ•°è¡¨

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| **ä¿å­˜ç›¸å…³** |
| `--save_dir` | str | `../out` | æ¨¡å‹ä¿å­˜ç›®å½• |
| `--save_weight` | str | `full_dist` | ä¿å­˜æƒé‡å‰ç¼€ |
| **è®­ç»ƒè¶…å‚æ•°** |
| `--epochs` | int | `6` | è®­ç»ƒè½®æ•° |
| `--batch_size` | int | `32` | æ‰¹æ¬¡å¤§å° |
| `--learning_rate` | float | `5e-6` | å­¦ä¹ ç‡ |
| `--device` | str | `cuda:0` | è®­ç»ƒè®¾å¤‡ |
| `--dtype` | str | `bfloat16` | æ··åˆç²¾åº¦ç±»å‹ |
| `--num_workers` | int | `4` | æ•°æ®åŠ è½½çº¿ç¨‹æ•° |
| `--accumulation_steps` | int | `1` | æ¢¯åº¦ç´¯ç§¯æ­¥æ•° |
| `--grad_clip` | float | `1.0` | æ¢¯åº¦è£å‰ªé˜ˆå€¼ |
| `--log_interval` | int | `100` | æ—¥å¿—æ‰“å°é—´éš” |
| `--save_interval` | int | `500` | ä¿å­˜é—´éš” |
| **æ¨¡å‹æ¶æ„** |
| `--max_seq_len` | int | `512` | æœ€å¤§åºåˆ—é•¿åº¦ |
| `--student_hidden_size` | int | `512` | å­¦ç”Ÿæ¨¡å‹éšè—å±‚ç»´åº¦ |
| `--student_num_layers` | int | `8` | å­¦ç”Ÿæ¨¡å‹å±‚æ•° |
| `--teacher_hidden_size` | int | `768` | æ•™å¸ˆæ¨¡å‹éšè—å±‚ç»´åº¦ |
| `--teacher_num_layers` | int | `16` | æ•™å¸ˆæ¨¡å‹å±‚æ•° |
| `--use_moe` | int | `0` | æ˜¯å¦ä½¿ç”¨ MoE |
| **æ•°æ®å’Œæƒé‡** |
| `--data_path` | str | `../dataset/sft_mini_512.jsonl` | è®­ç»ƒæ•°æ®è·¯å¾„ |
| `--from_student_weight` | str | `full_sft` | å­¦ç”Ÿæ¨¡å‹åˆå§‹æƒé‡ |
| `--from_teacher_weight` | str | `full_sft` | æ•™å¸ˆæ¨¡å‹æƒé‡ |
| `--from_resume` | int | `0` | æ˜¯å¦ç»­è®­ |
| **è’¸é¦ç‰¹å®šå‚æ•°** |
| `--alpha` | float | `0.5` | CE æŸå¤±æƒé‡ |
| `--temperature` | float | `1.5` | è’¸é¦æ¸©åº¦ |
| **æ—¥å¿—** |
| `--use_wandb` | flag | `False` | æ˜¯å¦ä½¿ç”¨ wandb |
| `--wandb_project` | str | `MiniMind-Distillation` | wandb é¡¹ç›®å |

### ğŸ’¡ å®ç”¨å‘½ä»¤ç¤ºä¾‹

#### Small â†’ Small ç™½ç›’è’¸é¦ï¼ˆå­¦ä¹ å‚è€ƒï¼‰
```bash
python trainer/train_distillation.py \
    --epochs 6 \
    --batch_size 32 \
    --learning_rate 5e-6 \
    --student_hidden_size 512 \
    --student_num_layers 8 \
    --teacher_hidden_size 512 \
    --teacher_num_layers 8 \
    --data_path ./dataset/sft_mini_512.jsonl \
    --from_student_weight pretrain \
    --from_teacher_weight full_sft \
    --alpha 0.5 \
    --temperature 1.5 \
    --save_weight full_dist
```

#### Base â†’ Small ç™½ç›’è’¸é¦
```bash
python trainer/train_distillation.py \
    --epochs 6 \
    --batch_size 16 \
    --learning_rate 3e-6 \
    --student_hidden_size 512 \
    --student_num_layers 8 \
    --teacher_hidden_size 768 \
    --teacher_num_layers 16 \
    --data_path ./dataset/sft_mini_512.jsonl \
    --from_student_weight pretrain \
    --from_teacher_weight full_sft \
    --alpha 0.3 \
    --temperature 2.0 \
    --save_weight dist_base_to_small
```

---

## 7. PPO è®­ç»ƒè„šæœ¬å‚æ•° â­

**è„šæœ¬**: `trainer/train_ppo.py`

### å‚æ•°è¡¨

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| **ä¿å­˜ç›¸å…³** |
| `--save_dir` | str | `../out` | æ¨¡å‹ä¿å­˜ç›®å½• |
| `--save_weight` | str | `ppo_actor` | ä¿å­˜æƒé‡å‰ç¼€ |
| **è®­ç»ƒè¶…å‚æ•°** |
| `--epochs` | int | `1` | è®­ç»ƒè½®æ•° |
| `--batch_size` | int | `2` | æ‰¹æ¬¡å¤§å°ï¼ˆâš ï¸ PPO éœ€è¦å¾ˆå° batchï¼‰ |
| `--learning_rate` | float | `8e-8` | Actor å­¦ä¹ ç‡ |
| `--critic_learning_rate` | float | `8e-8` | Critic å­¦ä¹ ç‡ |
| `--device` | str | `cuda:0` | è®­ç»ƒè®¾å¤‡ |
| `--dtype` | str | `bfloat16` | æ··åˆç²¾åº¦ç±»å‹ |
| `--num_workers` | int | `1` | æ•°æ®åŠ è½½çº¿ç¨‹æ•° |
| `--accumulation_steps` | int | `1` | æ¢¯åº¦ç´¯ç§¯æ­¥æ•° |
| `--grad_clip` | float | `1.0` | æ¢¯åº¦è£å‰ªé˜ˆå€¼ |
| `--log_interval` | int | `1` | æ—¥å¿—æ‰“å°é—´éš” |
| `--save_interval` | int | `10` | ä¿å­˜é—´éš” |
| **æ¨¡å‹æ¶æ„** |
| `--hidden_size` | int | `512` | éšè—å±‚ç»´åº¦ |
| `--num_hidden_layers` | int | `8` | Transformer å±‚æ•° |
| `--use_moe` | int | `0` | æ˜¯å¦ä½¿ç”¨ MoE |
| `--max_seq_len` | int | `66` | Prompt æœ€å¤§é•¿åº¦ |
| `--max_gen_len` | int | `1536` | ç”Ÿæˆæœ€å¤§é•¿åº¦ |
| **æ•°æ®å’Œæƒé‡** |
| `--data_path` | str | `../dataset/rlaif-mini.jsonl` | RLAIF æ•°æ®è·¯å¾„ |
| `--from_resume` | int | `0` | æ˜¯å¦ç»­è®­ |
| **PPO ç‰¹å®šå‚æ•°** |
| `--clip_epsilon` | float | `0.1` | PPO è£å‰ªå‚æ•° |
| `--vf_coef` | float | `0.5` | Value function ç³»æ•° |
| `--kl_coef` | float | `0.02` | KL æ•£åº¦æƒ©ç½šç³»æ•° |
| `--reasoning` | int | `1` | æ˜¯å¦ä¸ºæ¨ç†æ¨¡å‹ (0/1) |
| `--update_old_actor_freq` | int | `4` | æ›´æ–° old_actor é¢‘ç‡ |
| `--reward_model_path` | str | `../../internlm2-1_8b-reward` | å¥–åŠ±æ¨¡å‹è·¯å¾„ |
| **æ—¥å¿—** |
| `--use_wandb` | flag | `False` | æ˜¯å¦ä½¿ç”¨ wandb |
| `--wandb_project` | str | `MiniMind-PPO` | wandb é¡¹ç›®å |

### ğŸ’¡ å®ç”¨å‘½ä»¤ç¤ºä¾‹

#### åŸºç¡€ PPO è®­ç»ƒï¼ˆæ¨ç†æ¨¡å‹ï¼‰
```bash
python trainer/train_ppo.py \
    --epochs 1 \
    --batch_size 2 \
    --learning_rate 8e-8 \
    --critic_learning_rate 8e-8 \
    --hidden_size 512 \
    --num_hidden_layers 8 \
    --max_seq_len 66 \
    --max_gen_len 1536 \
    --data_path ./dataset/rlaif-mini.jsonl \
    --clip_epsilon 0.1 \
    --vf_coef 0.5 \
    --kl_coef 0.02 \
    --reasoning 1 \
    --reward_model_path ../internlm2-1_8b-reward \
    --save_weight ppo_actor
```

#### PPO è®­ç»ƒï¼ˆæ™®é€šæ¨¡å‹ï¼‰
```bash
python trainer/train_ppo.py \
    --epochs 1 \
    --batch_size 2 \
    --learning_rate 8e-8 \
    --critic_learning_rate 8e-8 \
    --hidden_size 512 \
    --num_hidden_layers 8 \
    --max_seq_len 128 \
    --max_gen_len 1024 \
    --data_path ./dataset/rlaif-mini.jsonl \
    --clip_epsilon 0.2 \
    --vf_coef 0.5 \
    --kl_coef 0.01 \
    --reasoning 0 \
    --reward_model_path ../internlm2-1_8b-reward \
    --save_weight ppo_actor
```

#### Base æ¨¡å‹ PPO è®­ç»ƒ
```bash
python trainer/train_ppo.py \
    --epochs 1 \
    --batch_size 1 \
    --learning_rate 5e-8 \
    --critic_learning_rate 5e-8 \
    --hidden_size 768 \
    --num_hidden_layers 16 \
    --max_seq_len 66 \
    --max_gen_len 1536 \
    --accumulation_steps 2 \
    --data_path ./dataset/rlaif-mini.jsonl \
    --clip_epsilon 0.1 \
    --vf_coef 0.5 \
    --kl_coef 0.02 \
    --reasoning 1 \
    --reward_model_path ../internlm2-1_8b-reward \
    --save_weight ppo_actor
```

---

## 8. GRPO è®­ç»ƒè„šæœ¬å‚æ•°

**è„šæœ¬**: `trainer/train_grpo.py`

### å‚æ•°è¡¨

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| **ä¿å­˜ç›¸å…³** |
| `--save_dir` | str | `../out` | æ¨¡å‹ä¿å­˜ç›®å½• |
| `--save_weight` | str | `grpo` | ä¿å­˜æƒé‡å‰ç¼€ |
| **è®­ç»ƒè¶…å‚æ•°** |
| `--epochs` | int | `1` | è®­ç»ƒè½®æ•° |
| `--batch_size` | int | `2` | æ‰¹æ¬¡å¤§å° |
| `--learning_rate` | float | `8e-8` | å­¦ä¹ ç‡ |
| `--device` | str | `cuda:0` | è®­ç»ƒè®¾å¤‡ |
| `--dtype` | str | `bfloat16` | æ··åˆç²¾åº¦ç±»å‹ |
| `--num_workers` | int | `1` | æ•°æ®åŠ è½½çº¿ç¨‹æ•° |
| `--accumulation_steps` | int | `1` | æ¢¯åº¦ç´¯ç§¯æ­¥æ•° |
| `--grad_clip` | float | `1.0` | æ¢¯åº¦è£å‰ªé˜ˆå€¼ |
| `--log_interval` | int | `1` | æ—¥å¿—æ‰“å°é—´éš” |
| `--save_interval` | int | `10` | ä¿å­˜é—´éš” |
| **æ¨¡å‹æ¶æ„** |
| `--hidden_size` | int | `512` | éšè—å±‚ç»´åº¦ |
| `--num_hidden_layers` | int | `8` | Transformer å±‚æ•° |
| `--use_moe` | int | `0` | æ˜¯å¦ä½¿ç”¨ MoE |
| `--max_seq_len` | int | `66` | è¾“å…¥æœ€å¤§é•¿åº¦ |
| `--max_gen_len` | int | `1536` | ç”Ÿæˆæœ€å¤§é•¿åº¦ |
| **æ•°æ®å’Œæƒé‡** |
| `--data_path` | str | `../dataset/rlaif-mini.jsonl` | GRPO æ•°æ®è·¯å¾„ |
| `--from_resume` | int | `0` | æ˜¯å¦ç»­è®­ |
| **GRPO ç‰¹å®šå‚æ•°** |
| `--num_generations` | int | `8` | æ¯ä¸ª prompt ç”Ÿæˆæ ·æœ¬æ•° |
| `--beta` | float | `0.02` | KL æƒ©ç½šç³»æ•° |
| `--reasoning` | int | `1` | æ˜¯å¦ä¸ºæ¨ç†æ¨¡å‹ |
| `--reward_model_path` | str | `./internlm2-1_8b-reward` | å¥–åŠ±æ¨¡å‹è·¯å¾„ |
| **æ—¥å¿—** |
| `--use_wandb` | flag | `False` | æ˜¯å¦ä½¿ç”¨ wandb |
| `--wandb_project` | str | `MiniMind-GRPO` | wandb é¡¹ç›®å |

### ğŸ’¡ å®ç”¨å‘½ä»¤ç¤ºä¾‹

#### åŸºç¡€ GRPO è®­ç»ƒ
```bash
python trainer/train_grpo.py \
    --epochs 1 \
    --batch_size 2 \
    --learning_rate 8e-8 \
    --hidden_size 512 \
    --num_hidden_layers 8 \
    --max_seq_len 66 \
    --max_gen_len 1536 \
    --data_path ./dataset/rlaif-mini.jsonl \
    --num_generations 8 \
    --beta 0.02 \
    --reasoning 1 \
    --reward_model_path ../internlm2-1_8b-reward \
    --save_weight grpo
```

#### æ›´å¤šç”Ÿæˆæ ·æœ¬çš„ GRPOï¼ˆæ›´å¥½çš„ç»„å†…å½’ä¸€åŒ–ï¼‰
```bash
python trainer/train_grpo.py \
    --epochs 1 \
    --batch_size 1 \
    --learning_rate 8e-8 \
    --hidden_size 512 \
    --num_hidden_layers 8 \
    --max_seq_len 66 \
    --max_gen_len 1536 \
    --data_path ./dataset/rlaif-mini.jsonl \
    --num_generations 16 \
    --beta 0.02 \
    --reasoning 1 \
    --reward_model_path ../internlm2-1_8b-reward \
    --save_weight grpo_gen16
```

#### Base æ¨¡å‹ GRPO è®­ç»ƒ
```bash
python trainer/train_grpo.py \
    --epochs 1 \
    --batch_size 1 \
    --learning_rate 5e-8 \
    --hidden_size 768 \
    --num_hidden_layers 16 \
    --max_seq_len 66 \
    --max_gen_len 1536 \
    --accumulation_steps 2 \
    --data_path ./dataset/rlaif-mini.jsonl \
    --num_generations 8 \
    --beta 0.02 \
    --reasoning 1 \
    --reward_model_path ../internlm2-1_8b-reward \
    --save_weight grpo
```

---

## 9. SPO è®­ç»ƒè„šæœ¬å‚æ•°

**è„šæœ¬**: `trainer/train_spo.py`

### å‚æ•°è¡¨

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| **ä¿å­˜ç›¸å…³** |
| `--save_dir` | str | `../out` | æ¨¡å‹ä¿å­˜ç›®å½• |
| `--save_weight` | str | `spo` | ä¿å­˜æƒé‡å‰ç¼€ |
| **è®­ç»ƒè¶…å‚æ•°** |
| `--epochs` | int | `1` | è®­ç»ƒè½®æ•° |
| `--batch_size` | int | `2` | æ‰¹æ¬¡å¤§å° |
| `--learning_rate` | float | `1e-7` | å­¦ä¹ ç‡ |
| `--device` | str | `cuda:0` | è®­ç»ƒè®¾å¤‡ |
| `--dtype` | str | `bfloat16` | æ··åˆç²¾åº¦ç±»å‹ |
| `--num_workers` | int | `1` | æ•°æ®åŠ è½½çº¿ç¨‹æ•° |
| `--accumulation_steps` | int | `4` | æ¢¯åº¦ç´¯ç§¯æ­¥æ•° |
| `--grad_clip` | float | `1.0` | æ¢¯åº¦è£å‰ªé˜ˆå€¼ |
| `--log_interval` | int | `1` | æ—¥å¿—æ‰“å°é—´éš” |
| `--save_interval` | int | `10` | ä¿å­˜é—´éš” |
| **æ¨¡å‹æ¶æ„** |
| `--hidden_size` | int | `512` | éšè—å±‚ç»´åº¦ |
| `--num_hidden_layers` | int | `8` | Transformer å±‚æ•° |
| `--use_moe` | int | `0` | æ˜¯å¦ä½¿ç”¨ MoE |
| `--max_seq_len` | int | `66` | è¾“å…¥æœ€å¤§é•¿åº¦ |
| `--max_gen_len` | int | `1536` | ç”Ÿæˆæœ€å¤§é•¿åº¦ |
| **æ•°æ®å’Œæƒé‡** |
| `--data_path` | str | `../dataset/rlaif-mini.jsonl` | SPO æ•°æ®è·¯å¾„ |
| `--from_resume` | int | `0` | æ˜¯å¦ç»­è®­ |
| **SPO ç‰¹å®šå‚æ•°** |
| `--beta` | float | `0.02` | KL æƒ©ç½šç³»æ•° |
| `--reasoning` | int | `1` | æ˜¯å¦ä¸ºæ¨ç†æ¨¡å‹ |
| `--reward_model_path` | str | `./internlm2-1_8b-reward` | å¥–åŠ±æ¨¡å‹è·¯å¾„ |
| **æ—¥å¿—** |
| `--use_wandb` | flag | `False` | æ˜¯å¦ä½¿ç”¨ wandb |
| `--wandb_project` | str | `MiniMind-SPO` | wandb é¡¹ç›®å |

### ğŸ’¡ å®ç”¨å‘½ä»¤ç¤ºä¾‹

#### åŸºç¡€ SPO è®­ç»ƒ
```bash
python trainer/train_spo.py \
    --epochs 1 \
    --batch_size 2 \
    --learning_rate 1e-7 \
    --hidden_size 512 \
    --num_hidden_layers 8 \
    --max_seq_len 66 \
    --max_gen_len 1536 \
    --accumulation_steps 4 \
    --data_path ./dataset/rlaif-mini.jsonl \
    --beta 0.02 \
    --reasoning 1 \
    --reward_model_path ../internlm2-1_8b-reward \
    --save_weight spo
```

---

## 10. API åœ¨çº¿è’¸é¦è®­ç»ƒå‚æ•° â­

**è„šæœ¬**: `trainer/train_distill_api.py`

### å‚æ•°è¡¨

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| **ä¿å­˜ç›¸å…³** |
| `--save_dir` | str | `../out` | æ¨¡å‹ä¿å­˜ç›®å½• |
| `--save_weight` | str | `api_distill` | ä¿å­˜æƒé‡å‰ç¼€ |
| **è®­ç»ƒè¶…å‚æ•°** |
| `--epochs` | int | `3` | è®­ç»ƒè½®æ•° |
| `--batch_size` | int | `4` | æ‰¹æ¬¡å¤§å°ï¼ˆå»ºè®®å°ä¸€ç‚¹ï¼‰ |
| `--learning_rate` | float | `5e-6` | å­¦ä¹ ç‡ |
| `--device` | str | `cuda:0` | è®­ç»ƒè®¾å¤‡ |
| `--dtype` | str | `bfloat16` | æ··åˆç²¾åº¦ç±»å‹ |
| `--num_workers` | int | `1` | æ•°æ®åŠ è½½çº¿ç¨‹æ•° |
| `--accumulation_steps` | int | `1` | æ¢¯åº¦ç´¯ç§¯æ­¥æ•° |
| `--grad_clip` | float | `1.0` | æ¢¯åº¦è£å‰ªé˜ˆå€¼ |
| `--log_interval` | int | `10` | æ—¥å¿—æ‰“å°é—´éš” |
| `--save_interval` | int | `100` | ä¿å­˜é—´éš” |
| **æ¨¡å‹æ¶æ„** |
| `--max_seq_len` | int | `512` | æœ€å¤§åºåˆ—é•¿åº¦ |
| `--hidden_size` | int | `512` | å­¦ç”Ÿæ¨¡å‹éšè—å±‚ç»´åº¦ |
| `--num_hidden_layers` | int | `8` | å­¦ç”Ÿæ¨¡å‹å±‚æ•° |
| `--use_moe` | int | `0` | æ˜¯å¦ä½¿ç”¨ MoE |
| **API é…ç½®** |
| `--api_key` | str | *å¿…éœ€* | OpenRouter API å¯†é’¥ |
| `--base_url` | str | `https://openrouter.ai/api/v1` | API åŸºç¡€ URL |
| `--teacher_model` | str | *å¿…éœ€* | æ•™å¸ˆæ¨¡å‹åç§° |
| `--api_temperature` | float | `0.7` | API è°ƒç”¨æ¸©åº¦ |
| `--distill_mode` | str | `text_distill` | è’¸é¦æ¨¡å¼ |
| **æ•°æ®å’Œæƒé‡** |
| `--data_path` | str | `../dataset/sft_mini_512.jsonl` | è®­ç»ƒæ•°æ®è·¯å¾„ |
| `--from_weight` | str | `full_sft` | å­¦ç”Ÿæ¨¡å‹åŸºäºå“ªä¸ªæƒé‡ |
| `--from_resume` | int | `0` | æ˜¯å¦ç»­è®­ |
| **æ—¥å¿—** |
| `--use_wandb` | flag | `False` | æ˜¯å¦ä½¿ç”¨ wandb |
| `--wandb_project` | str | `MiniMind-API-Distillation` | wandb é¡¹ç›®å |

### ğŸ’¡ å®ç”¨å‘½ä»¤ç¤ºä¾‹

#### åŸºç¡€ API åœ¨çº¿è’¸é¦ï¼ˆClaude Sonnet 4.5ï¼‰
```bash
python trainer/train_distill_api.py \
    --epochs 3 \
    --batch_size 4 \
    --learning_rate 5e-6 \
    --hidden_size 512 \
    --num_hidden_layers 8 \
    --max_seq_len 512 \
    --data_path ./dataset/sft_mini_512.jsonl \
    --from_weight full_sft \
    --api_key YOUR_OPENROUTER_KEY \
    --teacher_model anthropic/claude-sonnet-4.5 \
    --api_temperature 0.7 \
    --save_weight api_distill_sonnet
```

#### API åœ¨çº¿è’¸é¦ï¼ˆDeepSeek-R1ï¼Œé«˜æ€§ä»·æ¯”ï¼‰
```bash
python trainer/train_distill_api.py \
    --epochs 3 \
    --batch_size 4 \
    --learning_rate 5e-6 \
    --hidden_size 512 \
    --num_hidden_layers 8 \
    --max_seq_len 512 \
    --data_path ./dataset/sft_mini_512.jsonl \
    --from_weight full_sft \
    --api_key YOUR_OPENROUTER_KEY \
    --teacher_model deepseek/deepseek-r1 \
    --api_temperature 0.7 \
    --save_weight api_distill_r1
```

#### API åœ¨çº¿è’¸é¦ï¼ˆGPT-4 Turboï¼‰
```bash
python trainer/train_distill_api.py \
    --epochs 3 \
    --batch_size 4 \
    --learning_rate 5e-6 \
    --hidden_size 512 \
    --num_hidden_layers 8 \
    --max_seq_len 512 \
    --data_path ./dataset/sft_mini_512.jsonl \
    --from_weight full_sft \
    --api_key YOUR_OPENROUTER_KEY \
    --teacher_model openai/gpt-4-turbo \
    --api_temperature 0.7 \
    --save_weight api_distill_gpt4
```

---

## 11. API è’¸é¦æ•°æ®ç”Ÿæˆå‚æ•° â­

**è„šæœ¬**: `dataset/generate_distill_data_from_api.py`

### å‚æ•°è¡¨

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| **API é…ç½®** |
| `--api_key` | str | *å¿…éœ€* | OpenRouter API å¯†é’¥ |
| `--base_url` | str | `https://openrouter.ai/api/v1` | API åŸºç¡€ URL |
| `--model` | str | *å¿…éœ€* | æ•™å¸ˆæ¨¡å‹åç§° |
| **æ–‡ä»¶è·¯å¾„** |
| `--input_file` | str | *å¿…éœ€* | è¾“å…¥æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆJSONLï¼‰ |
| `--output_file` | str | *å¿…éœ€* | è¾“å‡ºæ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆJSONLï¼‰ |
| `--mode` | str | `answer_only` | è¾“å‡ºæ¨¡å¼ï¼ˆanswer_only/reasoningï¼‰ |
| **ç”Ÿæˆå‚æ•°** |
| `--temperature` | float | `0.7` | æ¸©åº¦å‚æ•° |
| `--max_tokens` | int | `2048` | æœ€å¤§ç”Ÿæˆ token æ•° |
| `--reasoning_effort` | str | - | æ¨ç†å¼ºåº¦ï¼ˆlow/medium/highï¼‰ |
| `--max_samples` | int | - | æœ€å¤§æ ·æœ¬æ•°ï¼ˆç”¨äºæµ‹è¯•ï¼‰ |
| `--no_resume` | flag | `False` | ç¦ç”¨æ–­ç‚¹ç»­ä¼  |
| `--rate_limit_delay` | float | `0.5` | API è°ƒç”¨é—´éš”ï¼ˆç§’ï¼‰ |

### ğŸ’¡ å®ç”¨å‘½ä»¤ç¤ºä¾‹

#### ç”Ÿæˆæ ‡å‡†è’¸é¦æ•°æ®ï¼ˆClaude Opus 4.5ï¼‰
```bash
python dataset/generate_distill_data_from_api.py \
    --api_key YOUR_OPENROUTER_KEY \
    --model anthropic/claude-opus-4.5 \
    --input_file ./dataset/sft_mini_512.jsonl \
    --output_file ./dataset/distill_opus45.jsonl \
    --mode answer_only \
    --temperature 0.7 \
    --max_tokens 2048 \
    --rate_limit_delay 1.0
```

#### ç”Ÿæˆæ¨ç†è’¸é¦æ•°æ®ï¼ˆDeepSeek-R1ï¼‰
```bash
python dataset/generate_distill_data_from_api.py \
    --api_key YOUR_OPENROUTER_KEY \
    --model deepseek/deepseek-r1 \
    --input_file ./dataset/sft_mini_512.jsonl \
    --output_file ./dataset/distill_r1_reasoning.jsonl \
    --mode reasoning \
    --reasoning_effort high \
    --temperature 0.8 \
    --max_tokens 4096 \
    --rate_limit_delay 1.0
```

#### æµ‹è¯•ç”Ÿæˆï¼ˆä»… 50 æ¡æ ·æœ¬ï¼‰
```bash
python dataset/generate_distill_data_from_api.py \
    --api_key YOUR_OPENROUTER_KEY \
    --model anthropic/claude-sonnet-4.5 \
    --input_file ./dataset/sft_mini_512.jsonl \
    --output_file ./dataset/distill_test.jsonl \
    --mode answer_only \
    --max_samples 50 \
    --rate_limit_delay 0.5
```

#### å¤§æ‰¹é‡ç”Ÿæˆï¼ˆé™ä½å»¶è¿Ÿï¼‰
```bash
python dataset/generate_distill_data_from_api.py \
    --api_key YOUR_OPENROUTER_KEY \
    --model google/gemini-3-flash-preview \
    --input_file ./dataset/sft_1024.jsonl \
    --output_file ./dataset/distill_gemini3.jsonl \
    --mode answer_only \
    --temperature 0.7 \
    --max_tokens 2048 \
    --rate_limit_delay 0.2
```

---

## 12. API é—®ç­”å¯¹ç”Ÿæˆå‚æ•° â­

**è„šæœ¬**: `dataset/generate_qa_pairs_from_api.py`

### å‚æ•°è¡¨

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| **API é…ç½®** |
| `--api_key` | str | *å¿…éœ€* | OpenRouter API å¯†é’¥ |
| `--model` | str | *å¿…éœ€* | æ•™å¸ˆæ¨¡å‹åç§° |
| **æ•°æ®é…ç½®** |
| `--topic` | str | *å¿…éœ€* | æ•°æ®ä¸»é¢˜ |
| `--num_samples` | int | *å¿…éœ€* | ç”Ÿæˆæ•°é‡ |
| `--output_file` | str | *å¿…éœ€* | è¾“å‡ºæ–‡ä»¶è·¯å¾„ |
| **ç”Ÿæˆå‚æ•°** |
| `--difficulty` | str | `medium` | éš¾åº¦ï¼ˆeasy/medium/hardï¼‰ |
| `--language` | str | `zh` | è¯­è¨€ï¼ˆzh/enï¼‰ |
| `--mode` | str | `answer_only` | è¾“å‡ºæ¨¡å¼ï¼ˆanswer_only/reasoningï¼‰ |
| `--temperature` | float | `0.8` | æ¸©åº¦å‚æ•° |
| `--rate_limit_delay` | float | `1.0` | API è°ƒç”¨é—´éš”ï¼ˆç§’ï¼‰ |
| `--no_resume` | flag | `False` | ç¦ç”¨æ–­ç‚¹ç»­ä¼  |

### ğŸ’¡ å®ç”¨å‘½ä»¤ç¤ºä¾‹

#### ç”Ÿæˆ Python ç¼–ç¨‹é—®ç­”æ•°æ®
```bash
python dataset/generate_qa_pairs_from_api.py \
    --api_key YOUR_OPENROUTER_KEY \
    --model anthropic/claude-sonnet-4.5 \
    --topic "Pythonç¼–ç¨‹åŸºç¡€å’Œè¿›é˜¶" \
    --num_samples 1000 \
    --output_file ./dataset/qa_python_1000.jsonl \
    --difficulty medium \
    --language zh \
    --mode answer_only \
    --temperature 0.8 \
    --rate_limit_delay 1.0
```

#### ç”Ÿæˆæ•°å­¦é—®ç­”æ•°æ®ï¼ˆå¸¦æ¨ç†è¿‡ç¨‹ï¼‰
```bash
python dataset/generate_qa_pairs_from_api.py \
    --api_key YOUR_OPENROUTER_KEY \
    --model deepseek/deepseek-r1 \
    --topic "åˆä¸­æ•°å­¦åº”ç”¨é¢˜" \
    --num_samples 500 \
    --output_file ./dataset/qa_math_500.jsonl \
    --difficulty medium \
    --language zh \
    --mode reasoning \
    --temperature 0.8 \
    --rate_limit_delay 1.0
```

#### ç”Ÿæˆè‹±è¯­è¯­æ³•æ•°æ®
```bash
python dataset/generate_qa_pairs_from_api.py \
    --api_key YOUR_OPENROUTER_KEY \
    --model anthropic/claude-sonnet-4.5 \
    --topic "English Grammar and Writing" \
    --num_samples 800 \
    --output_file ./dataset/qa_english_800.jsonl \
    --difficulty hard \
    --language en \
    --mode answer_only \
    --temperature 0.9 \
    --rate_limit_delay 1.0
```

#### ç”Ÿæˆç®€å•æ•°æ®ï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰
```bash
python dataset/generate_qa_pairs_from_api.py \
    --api_key YOUR_OPENROUTER_KEY \
    --model google/gemini-3-flash-preview \
    --topic "æ—¥å¸¸ç”Ÿæ´»å¸¸è¯†" \
    --num_samples 100 \
    --output_file ./dataset/qa_test.jsonl \
    --difficulty easy \
    --language zh \
    --mode answer_only \
    --temperature 0.8 \
    --rate_limit_delay 0.5
```

---

## 13. æ¨ç†è„šæœ¬å‚æ•°

**è„šæœ¬**: `scripts/eval_llm.py`

### å‚æ•°è¡¨

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| **æ¨¡å‹åŠ è½½** |
| `--load_from` | str | `model` | æ¨¡å‹åŠ è½½è·¯å¾„ |
| `--save_dir` | str | `out` | æƒé‡ç›®å½• |
| `--weight` | str | `full_sft` | æƒé‡åç§° |
| `--lora_weight` | str | `None` | LoRA æƒé‡åç§° |
| **æ¨¡å‹æ¶æ„** |
| `--hidden_size` | int | `512` | éšè—å±‚ç»´åº¦ |
| `--num_hidden_layers` | int | `8` | Transformer å±‚æ•° |
| `--use_moe` | int | `0` | æ˜¯å¦ä½¿ç”¨ MoE |
| `--inference_rope_scaling` | flag | `False` | å¯ç”¨ RoPE å¤–æ¨ |
| **ç”Ÿæˆå‚æ•°** |
| `--max_new_tokens` | int | `8192` | æœ€å¤§ç”Ÿæˆ token æ•° |
| `--temperature` | float | `0.85` | ç”Ÿæˆæ¸©åº¦ |
| `--top_p` | float | `0.85` | Top-p é‡‡æ · |
| **å¯¹è¯å‚æ•°** |
| `--historys` | int | `0` | æºå¸¦å†å²å¯¹è¯è½®æ•° |
| **è®¾å¤‡** |
| `--device` | str | `cuda` | è¿è¡Œè®¾å¤‡ |

### ğŸ’¡ å®ç”¨å‘½ä»¤ç¤ºä¾‹

#### åŸºç¡€æ¨ç†ï¼ˆSFT æ¨¡å‹ï¼‰
```bash
python scripts/eval_llm.py \
    --weight full_sft \
    --hidden_size 512 \
    --num_hidden_layers 8
```

#### æ¨ç†æ¨¡å‹æµ‹è¯•
```bash
python scripts/eval_llm.py \
    --weight reason \
    --hidden_size 512 \
    --num_hidden_layers 8 \
    --temperature 0.8
```

#### ä½¿ç”¨ LoRA æƒé‡
```bash
python scripts/eval_llm.py \
    --weight dpo \
    --lora_weight lora_medical \
    --hidden_size 512 \
    --num_hidden_layers 8
```

#### å¤šè½®å¯¹è¯ï¼ˆä¿ç•™å†å²ï¼‰
```bash
python scripts/eval_llm.py \
    --weight full_sft \
    --historys 6 \
    --hidden_size 512 \
    --num_hidden_layers 8
```

#### é•¿æ–‡æœ¬æ¨ç†ï¼ˆRoPE å¤–æ¨ï¼‰
```bash
python scripts/eval_llm.py \
    --weight full_sft \
    --inference_rope_scaling \
    --max_new_tokens 4096 \
    --hidden_size 512 \
    --num_hidden_layers 8
```

#### Base æ¨¡å‹æ¨ç†
```bash
python scripts/eval_llm.py \
    --weight full_sft \
    --hidden_size 768 \
    --num_hidden_layers 16
```

#### CPU æ¨ç†
```bash
python scripts/eval_llm.py \
    --weight full_sft \
    --device cpu \
    --hidden_size 512 \
    --num_hidden_layers 8
```

#### HuggingFace æ ¼å¼æ¨¡å‹
```bash
python scripts/eval_llm.py \
    --load_from ./MiniMind2
```

---

## ğŸ“Š é™„å½•ï¼šå‚æ•°æ¨è

### å­¦ä¹ ç‡æ¨è

| è®­ç»ƒé˜¶æ®µ | æ¨èå­¦ä¹ ç‡ | è¯´æ˜ |
|----------|------------|------|
| é¢„è®­ç»ƒ | 5e-4 ~ 1e-3 | å¯ä»¥ç”¨è¾ƒå¤§å­¦ä¹ ç‡ |
| SFT | 5e-7 ~ 5e-6 | éœ€è¦å°å­¦ä¹ ç‡é¿å…é—å¿˜ |
| LoRA | 1e-4 ~ 5e-4 | LoRA å¯ä»¥ç”¨è¾ƒå¤§å­¦ä¹ ç‡ |
| DPO | 1e-8 ~ 5e-8 | éœ€è¦æå°å­¦ä¹ ç‡ |
| è’¸é¦ | 1e-6 ~ 5e-6 | ä¸­ç­‰å­¦ä¹ ç‡ |
| PPO/GRPO/SPO | 5e-8 ~ 1e-7 | éœ€è¦å°å­¦ä¹ ç‡ |
| APIè’¸é¦ | 5e-6 ~ 1e-5 | ä¸­ç­‰å­¦ä¹ ç‡ |

### æ‰¹æ¬¡å¤§å°æ¨è

| æ˜¾å­˜ | é¢„è®­ç»ƒ | SFT | DPO | LoRA | PPO/GRPO | è’¸é¦ |
|------|--------|-----|-----|------|----------|------|
| 8GB | 8 | 4 | 1 | 16 | 1 | 8 |
| 16GB | 32 | 16 | 4 | 32 | 2 | 16 |
| 24GB | 64 | 32 | 8 | 64 | 4 | 32 |
| 80GB | 128 | 64 | 16 | 128 | 8 | 64 |

### æ¨¡å‹è§„æ ¼å¯¹ç…§

| æ¨¡å‹ | hidden_size | num_layers | å‚æ•°é‡ |
|------|-------------|------------|--------|
| Small | 512 | 8 | 26M |
| Base | 768 | 16 | 104M |
| MoE | 640 | 8 | 145M |

---

## ğŸ¯ å®Œæ•´è®­ç»ƒæµç¨‹ç¤ºä¾‹

### ä»é›¶è®­ç»ƒä¸€ä¸ªå®Œæ•´çš„ MiniMind æ¨¡å‹

```bash
# 1. é¢„è®­ç»ƒï¼ˆå­¦çŸ¥è¯†ï¼‰
python trainer/train_pretrain.py \
    --epochs 1 \
    --batch_size 32 \
    --learning_rate 5e-4 \
    --data_path ./dataset/pretrain_hq.jsonl \
    --save_weight pretrain

# 2. ç›‘ç£å¾®è°ƒï¼ˆå­¦å¯¹è¯ï¼‰
python trainer/train_full_sft.py \
    --epochs 2 \
    --batch_size 16 \
    --learning_rate 5e-7 \
    --data_path ./dataset/sft_mini_512.jsonl \
    --from_weight pretrain \
    --save_weight full_sft

# 3. DPO å¯¹é½ï¼ˆå­¦åå¥½ï¼‰
python trainer/train_dpo.py \
    --epochs 1 \
    --batch_size 4 \
    --learning_rate 4e-8 \
    --data_path ./dataset/dpo.jsonl \
    --from_weight full_sft \
    --save_weight dpo

# 4. æ¨ç†è’¸é¦ï¼ˆå­¦æ¨ç†ï¼‰
python trainer/train_distill_reason.py \
    --epochs 1 \
    --batch_size 8 \
    --learning_rate 1e-6 \
    --data_path ./dataset/r1_mix_1024.jsonl \
    --from_weight dpo \
    --save_weight reason

# 5. æµ‹è¯•æ¨¡å‹
python scripts/eval_llm.py --weight reason
```

---

## ğŸ“ å¿«é€Ÿå‚è€ƒå¡

| æƒ³åšä»€ä¹ˆ | ç”¨ä»€ä¹ˆè„šæœ¬ | æ ¸å¿ƒå‚æ•° |
|---------|-----------|---------|
| ä»å¤´è®­ç»ƒ | `train_pretrain.py` | `--epochs 1 --batch_size 32 --learning_rate 5e-4` |
| æŒ‡ä»¤å¾®è°ƒ | `train_full_sft.py` | `--epochs 2 --batch_size 16 --learning_rate 5e-7` |
| åå¥½å¯¹é½ | `train_dpo.py` | `--epochs 1 --batch_size 4 --learning_rate 4e-8` |
| æ¨ç†è’¸é¦ | `train_distill_reason.py` | `--epochs 1 --batch_size 8 --learning_rate 1e-6` |
| å¼ºåŒ–å­¦ä¹  | `train_grpo.py` / `train_ppo.py` | `--num_generations 8 --beta 0.02` |
| å‚æ•°é«˜æ•ˆå¾®è°ƒ | `train_lora.py` | `--epochs 50 --learning_rate 1e-4` |
| APIè’¸é¦æ•°æ®ç”Ÿæˆ | `generate_distill_data_from_api.py` | `--model xxx --mode reasoning` |
| APIé—®ç­”ç”Ÿæˆ | `generate_qa_pairs_from_api.py` | `--topic xxx --num_samples 1000` |
| æ¨¡å‹æ¨ç† | `eval_llm.py` | `--weight full_sft` |

---

**æ›´æ–°æ—¶é—´**: 2025-01-XX  
**ç‰ˆæœ¬**: v2.0ï¼ˆå®Œæ•´ç‰ˆï¼‰

