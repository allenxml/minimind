# è·¯å¾„æ›´æ–°è¡¥å……è¯´æ˜

## ğŸ“‹ æ¦‚è¿°

åœ¨å®Œæˆç›®å½•ç»“æ„é‡ç»„åï¼Œå¯¹ä»£ç å’Œè„šæœ¬å†…éƒ¨çš„è·¯å¾„å¼•ç”¨è¿›è¡Œäº†å…¨é¢æ£€æŸ¥å’Œæ›´æ–°ã€‚

---

## âœ… å·²ä¿®å¤çš„å†…éƒ¨è·¯å¾„

### 1. dataset/train_tokenizer.py

**ä¿®æ”¹ä½ç½®**: ç¬¬ 23 è¡Œ

```python
# ä¿®æ”¹å‰
data_path = '../dataset/pretrain_hq.jsonl'

# ä¿®æ”¹å
data_path = './pretrain_hq.jsonl'  # è„šæœ¬ç°åœ¨åœ¨ dataset/ ç›®å½•ä¸‹
```

**åŸå› **: è„šæœ¬ä» `scripts/` ç§»åŠ¨åˆ° `dataset/` åï¼Œç›¸å¯¹è·¯å¾„éœ€è¦è°ƒæ•´ã€‚

**å…¶ä»–è·¯å¾„**: 
- ç¬¬ 55 è¡Œ: `tokenizer_dir = "../model/"` âœ“ æ­£ç¡®ï¼ˆdataset/ â†’ ../model/ï¼‰
- ç¬¬ 58 è¡Œ: `tokenizer.model.save("../model/")` âœ“ æ­£ç¡®
- ç¬¬ 116 è¡Œ: `AutoTokenizer.from_pretrained("../model/")` âœ“ æ­£ç¡®

---

### 2. examples/api_distillation_example.sh

**ä¿®æ”¹ä½ç½®**: ç¬¬ 50ã€64 è¡Œ

```bash
# ä¿®æ”¹å‰
python dataset/generate_distill_data_from_api.py \
    ...
python trainer/train_distill_reason.py \

# ä¿®æ”¹å
python ../dataset/generate_distill_data_from_api.py \
    ...
python ../trainer/train_distill_reason.py \
```

**åŸå› **: ç¤ºä¾‹è„šæœ¬åœ¨ `examples/` ç›®å½•ä¸‹æ‰§è¡Œï¼Œéœ€è¦ä½¿ç”¨ç›¸å¯¹è·¯å¾„ `../` æ¥è®¿é—®çˆ¶ç›®å½•çš„å…¶ä»–æ¨¡å—ã€‚

**è·¯å¾„è¯´æ˜**:
- ç¬¬ 78 è¡Œ: `python ../scripts/infer_chat.py` âœ“ å·²æ­£ç¡®

---

## ğŸ“„ å·²æ›´æ–°çš„æ–‡æ¡£æ–‡ä»¶

### ä¸»æ–‡æ¡£ï¼ˆå·²åœ¨å‰æ¬¡æ›´æ–°ï¼‰
1. âœ… `README.md` - 7 å¤„
2. âœ… `docs/APIè’¸é¦è®­ç»ƒæŒ‡å—.md` - 8 å¤„
3. âœ… `examples/README.md` - 1 å¤„
4. âœ… `examples/api_distillation_example.sh` - 2 å¤„

### è¡¥å……æ›´æ–°çš„æ–‡æ¡£ï¼ˆæœ¬æ¬¡æ–°å¢ï¼‰
5. âœ… `docs/å¿«é€Ÿå¼€å§‹.md` - 3 å¤„
6. âœ… `docs/æ¨ç†éƒ¨ç½².md` - 8 å¤„
7. âœ… `docs/è®­ç»ƒæŒ‡å—.md` - 1 å¤„
8. âœ… `docs/æ“ä½œç¤ºä¾‹.md` - 16 å¤„
9. âœ… `docs/å‘½ä»¤è¡Œå‚æ•°å¤§å…¨.md` - 1 å¤„
10. âœ… `README_en.md` - 4 å¤„ï¼ˆè‹±æ–‡ç‰ˆï¼‰

---

## ğŸ“Š æ›´æ–°ç»Ÿè®¡

| ç±»å‹ | æ–‡ä»¶æ•° | ä¿®æ”¹å¤„æ•° |
|------|--------|----------|
| Python è„šæœ¬å†…éƒ¨è·¯å¾„ | 2 | 3 |
| Shell è„šæœ¬å†…éƒ¨è·¯å¾„ | 1 | 2 |
| ä¸­æ–‡æ–‡æ¡£ | 8 | 44+ |
| è‹±æ–‡æ–‡æ¡£ | 1 | 4 |
| **æ€»è®¡** | **12** | **53+** |

---

## ğŸ” è·¯å¾„æ£€æŸ¥æ¸…å•

### å·²å®Œæˆ âœ“

- [x] `dataset/generate_distill_data_from_api.py` - æ— å†…éƒ¨è·¯å¾„ä¾èµ–
- [x] `dataset/generate_qa_pairs_from_api.py` - æ— å†…éƒ¨è·¯å¾„ä¾èµ–
- [x] `dataset/train_tokenizer.py` - å·²ä¿®å¤æ•°æ®è·¯å¾„
- [x] `scripts/eval_llm.py` - å·²æ·»åŠ  sys.path å¤„ç†
- [x] `examples/api_distillation_example.sh` - å·²ä¿®å¤æ‰€æœ‰ç›¸å¯¹è·¯å¾„
- [x] æ‰€æœ‰ä¸­è‹±æ–‡æ–‡æ¡£ - å·²å…¨é¢æ›´æ–°

### éªŒè¯é€šè¿‡ âœ“

- [x] `dataset/train_tokenizer.py` çš„ `../model/` è·¯å¾„æ­£ç¡®
- [x] `scripts/eval_llm.py` çš„å¯¼å…¥è·¯å¾„æ­£ç¡®
- [x] `examples/` ç›®å½•ä¸‹è„šæœ¬çš„ç›¸å¯¹è·¯å¾„æ­£ç¡®

---

## ğŸ¯ ä½¿ç”¨å½±å“

### ç”¨æˆ·æ— æ„ŸçŸ¥

ä»¥ä¸‹è·¯å¾„è°ƒæ•´å¯¹ç”¨æˆ·é€æ˜ï¼Œæ— éœ€æ‰‹åŠ¨ä¿®æ”¹ï¼š
- âœ… æ–‡æ¡£ä¸­çš„ç¤ºä¾‹ä»£ç å·²å…¨éƒ¨åŒæ­¥æ›´æ–°
- âœ… è„šæœ¬å†…éƒ¨è·¯å¾„å·²è‡ªåŠ¨è°ƒæ•´
- âœ… æ‰€æœ‰ç›¸å¯¹è·¯å¾„å·²æ­£ç¡®é…ç½®

### ä½¿ç”¨æ–¹å¼å˜æ›´

ç”¨æˆ·éœ€è¦æ³¨æ„çš„æ–°å‘½ä»¤æ ¼å¼ï¼š

```bash
# âœ… æ­£ç¡®çš„æ–°å‘½ä»¤
python scripts/eval_llm.py
python dataset/generate_distill_data_from_api.py
python dataset/generate_qa_pairs_from_api.py
python dataset/train_tokenizer.py

# âŒ æ—§å‘½ä»¤ï¼ˆä¸å†æœ‰æ•ˆï¼‰
python eval_llm.py
python scripts/generate_distill_data_from_api.py
python scripts/generate_qa_pairs_from_api.py
python scripts/train_tokenizer.py
```

---

## ğŸ”„ è¿ç§»å»ºè®®

å¦‚æœä½ æœ‰è‡ªå®šä¹‰è„šæœ¬è°ƒç”¨äº†è¿™äº›æ–‡ä»¶ï¼Œè¯·æ›´æ–°ä¸ºæ–°è·¯å¾„ï¼š

### ç¤ºä¾‹ï¼šè‡ªå®šä¹‰è®­ç»ƒè„šæœ¬

```python
# ä¿®æ”¹å‰
import sys
sys.path.append('scripts')
from generate_distill_data_from_api import OpenRouterClient

# ä¿®æ”¹å
import sys
sys.path.append('dataset')
from generate_distill_data_from_api import OpenRouterClient
```

### ç¤ºä¾‹ï¼šShell è„šæœ¬

```bash
# ä¿®æ”¹å‰
python eval_llm.py --weight full_sft

# ä¿®æ”¹å
python scripts/eval_llm.py --weight full_sft
```

---

## âœ… éªŒè¯å®Œæˆ

æ‰€æœ‰è·¯å¾„æ›´æ–°å·²å®Œæˆå¹¶éªŒè¯é€šè¿‡ã€‚é¡¹ç›®ç°åœ¨å¤„äºå®Œå…¨å¯ç”¨çŠ¶æ€ã€‚

### å¿«é€ŸéªŒè¯å‘½ä»¤

```bash
# éªŒè¯ eval_llm.py
python scripts/eval_llm.py --help

# éªŒè¯æ•°æ®ç”Ÿæˆè„šæœ¬
python dataset/generate_distill_data_from_api.py --help
python dataset/generate_qa_pairs_from_api.py --help

# éªŒè¯ tokenizer è®­ç»ƒ
cd dataset && python train_tokenizer.py
```

---

**æ›´æ–°æ—¶é—´**: 2025-01-XX  
**çŠ¶æ€**: âœ… å…¨éƒ¨å®Œæˆ

