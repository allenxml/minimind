#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SafeTensors ä½¿ç”¨ç¤ºä¾‹

æœ¬è„šæœ¬æ¼”ç¤ºå¦‚ä½•åœ¨ MiniMind ä¸­ä½¿ç”¨ SafeTensors æ ¼å¼
"""

import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import torch
from model.model_minimind import MiniMindConfig, MiniMindForCausalLM
from trainer.trainer_utils import (
    init_model, 
    save_model_safetensors, 
    load_model_safetensors,
    SAFETENSORS_AVAILABLE
)


def example_1_check_availability():
    """ç¤ºä¾‹1: æ£€æŸ¥ SafeTensors æ˜¯å¦å¯ç”¨"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹1: æ£€æŸ¥ SafeTensors å¯ç”¨æ€§")
    print("="*60)
    
    if SAFETENSORS_AVAILABLE:
        print("âœ… SafeTensors å·²å®‰è£…å¹¶å¯ç”¨")
        from safetensors import __version__
        print(f"   ç‰ˆæœ¬: {__version__}")
    else:
        print("âŒ SafeTensors æœªå®‰è£…")
        print("   å®‰è£…æ–¹æ³•: pip install safetensors")


def example_2_save_model():
    """ç¤ºä¾‹2: ä¿å­˜æ¨¡å‹ä¸º SafeTensors æ ¼å¼"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹2: ä¿å­˜æ¨¡å‹ä¸º SafeTensors æ ¼å¼")
    print("="*60)
    
    # åˆ›å»ºä¸€ä¸ªå°æ¨¡å‹
    config = MiniMindConfig(hidden_size=256, num_hidden_layers=4)
    model = MiniMindForCausalLM(config)
    
    print(f"æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()) / 1e6:.2f}M")
    
    # ä¿å­˜ä¸º SafeTensors
    output_path = "out/example_model.safetensors"
    os.makedirs("out", exist_ok=True)
    
    success = save_model_safetensors(model, output_path, half_precision=True)
    
    if success:
        file_size = os.path.getsize(output_path) / (1024**2)
        print(f"âœ… æ¨¡å‹å·²ä¿å­˜: {output_path}")
        print(f"   æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
    
    return output_path


def example_3_load_model():
    """ç¤ºä¾‹3: ä» SafeTensors åŠ è½½æ¨¡å‹"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹3: ä» SafeTensors åŠ è½½æ¨¡å‹")
    print("="*60)
    
    if not SAFETENSORS_AVAILABLE:
        print("âš ï¸  SafeTensors æœªå®‰è£…ï¼Œè·³è¿‡æ­¤ç¤ºä¾‹")
        return
    
    # ç¡®ä¿æœ‰æ¨¡å‹æ–‡ä»¶
    model_path = "out/example_model.safetensors"
    if not os.path.exists(model_path):
        print(f"âš ï¸  æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        print("   è¿è¡Œç¤ºä¾‹2å…ˆåˆ›å»ºæ¨¡å‹")
        return
    
    # åˆ›å»ºæ¨¡å‹æ¶æ„
    config = MiniMindConfig(hidden_size=256, num_hidden_layers=4)
    model = MiniMindForCausalLM(config)
    
    # åŠ è½½æƒé‡
    state_dict = load_model_safetensors(model_path, device='cpu')
    model.load_state_dict(state_dict)
    
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    print(f"   å‚æ•°é‡: {sum(p.numel() for p in model.parameters()) / 1e6:.2f}M")


def example_4_compare_formats():
    """ç¤ºä¾‹4: å¯¹æ¯” PyTorch å’Œ SafeTensors æ ¼å¼"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹4: å¯¹æ¯”ä¸åŒæ ¼å¼çš„æ€§èƒ½")
    print("="*60)
    
    import time
    
    # åˆ›å»ºæ¨¡å‹
    config = MiniMindConfig(hidden_size=512, num_hidden_layers=8)
    model = MiniMindForCausalLM(config)
    
    os.makedirs("out", exist_ok=True)
    
    # ä¿å­˜ä¸º PyTorch æ ¼å¼
    pth_path = "out/compare_model.pth"
    print("\nğŸ“ ä¿å­˜ä¸º PyTorch æ ¼å¼...")
    start = time.time()
    torch.save(model.state_dict(), pth_path)
    pth_save_time = time.time() - start
    pth_size = os.path.getsize(pth_path) / (1024**2)
    print(f"   ä¿å­˜æ—¶é—´: {pth_save_time:.3f}ç§’")
    print(f"   æ–‡ä»¶å¤§å°: {pth_size:.2f} MB")
    
    # ä¿å­˜ä¸º SafeTensors æ ¼å¼
    if SAFETENSORS_AVAILABLE:
        safe_path = "out/compare_model.safetensors"
        print("\nğŸ“ ä¿å­˜ä¸º SafeTensors æ ¼å¼...")
        start = time.time()
        save_model_safetensors(model, safe_path, half_precision=False)
        safe_save_time = time.time() - start
        safe_size = os.path.getsize(safe_path) / (1024**2)
        print(f"   ä¿å­˜æ—¶é—´: {safe_save_time:.3f}ç§’")
        print(f"   æ–‡ä»¶å¤§å°: {safe_size:.2f} MB")
        
        # åŠ è½½æ€§èƒ½å¯¹æ¯”
        print("\nğŸ“‚ åŠ è½½æ€§èƒ½å¯¹æ¯”...")
        
        # åŠ è½½ PyTorch
        start = time.time()
        _ = torch.load(pth_path, map_location='cpu')
        pth_load_time = time.time() - start
        print(f"   PyTorch åŠ è½½æ—¶é—´: {pth_load_time:.3f}ç§’")
        
        # åŠ è½½ SafeTensors
        start = time.time()
        _ = load_model_safetensors(safe_path, device='cpu')
        safe_load_time = time.time() - start
        print(f"   SafeTensors åŠ è½½æ—¶é—´: {safe_load_time:.3f}ç§’")
        
        # æ€»ç»“
        print("\n" + "="*60)
        print("ğŸ“Š æ€§èƒ½å¯¹æ¯”æ€»ç»“")
        print("="*60)
        print(f"ä¿å­˜æ—¶é—´: SafeTensors æ¯” PyTorch å¿« {pth_save_time/safe_save_time:.2f}x")
        print(f"åŠ è½½æ—¶é—´: SafeTensors æ¯” PyTorch å¿« {pth_load_time/safe_load_time:.2f}x âš¡")
        print(f"æ–‡ä»¶å¤§å°: åŸºæœ¬ç›¸åŒ ({abs(safe_size-pth_size):.2f} MB å·®å¼‚)")


def example_5_auto_load():
    """ç¤ºä¾‹5: ä½¿ç”¨ init_model è‡ªåŠ¨é€‰æ‹©æ ¼å¼"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹5: è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ ¼å¼åŠ è½½")
    print("="*60)
    
    # ç¡®ä¿æœ‰æµ‹è¯•æ–‡ä»¶
    if not os.path.exists("out/compare_model.safetensors"):
        print("âš ï¸  éœ€è¦å…ˆè¿è¡Œç¤ºä¾‹4åˆ›å»ºæµ‹è¯•æ–‡ä»¶")
        return
    
    config = MiniMindConfig(hidden_size=512, num_hidden_layers=8)
    
    # ä¼˜å…ˆåŠ è½½ SafeTensorsï¼ˆé»˜è®¤ï¼‰
    print("\nğŸ” æµ‹è¯•1: ä¼˜å…ˆåŠ è½½ SafeTensors")
    try:
        model, _ = init_model(
            config,
            from_weight='compare_model',
            save_dir='out',
            tokenizer_path='model',
            device='cpu',
            prefer_safetensors=True  # é»˜è®¤
        )
        print("âœ… æˆåŠŸåŠ è½½ï¼ˆä¼˜å…ˆ SafeTensorsï¼‰")
    except Exception as e:
        print(f"âŒ åŠ è½½å¤±è´¥: {e}")
    
    # ä»…åŠ è½½ PyTorch æ ¼å¼
    print("\nğŸ” æµ‹è¯•2: ä»…åŠ è½½ PyTorch æ ¼å¼")
    try:
        model, _ = init_model(
            config,
            from_weight='compare_model',
            save_dir='out',
            tokenizer_path='model',
            device='cpu',
            prefer_safetensors=False
        )
        print("âœ… æˆåŠŸåŠ è½½ï¼ˆPyTorch æ ¼å¼ï¼‰")
    except Exception as e:
        print(f"âŒ åŠ è½½å¤±è´¥: {e}")


def example_6_convert_existing():
    """ç¤ºä¾‹6: è½¬æ¢ç°æœ‰æ¨¡å‹"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹6: ä½¿ç”¨è½¬æ¢è„šæœ¬")
    print("="*60)
    
    print("""
è½¬æ¢ç°æœ‰æ¨¡å‹çš„æ–¹æ³•ï¼š

1. è½¬æ¢å•ä¸ªæ–‡ä»¶:
   python scripts/convert_to_safetensors.py out/pretrain_512.pth

2. æ‰¹é‡è½¬æ¢:
   python scripts/convert_to_safetensors.py --batch out/

3. æŒ‡å®šè¾“å‡ºè·¯å¾„:
   python scripts/convert_to_safetensors.py out/model.pth --output models/model.safetensors

4. è·³è¿‡éªŒè¯ï¼ˆæ›´å¿«ï¼‰:
   python scripts/convert_to_safetensors.py out/model.pth --no-verify

è¯¦ç»†ç”¨æ³•è¯·å‚è€ƒ: SafeTensorsä½¿ç”¨æŒ‡å—.md
    """)


def main():
    """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘         SafeTensors ä½¿ç”¨ç¤ºä¾‹                               â•‘
â•‘         MiniMind Project                                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
    example_1_check_availability()
    
    if SAFETENSORS_AVAILABLE:
        example_2_save_model()
        example_3_load_model()
        example_4_compare_formats()
        example_5_auto_load()
    else:
        print("\nâš ï¸  SafeTensors æœªå®‰è£…ï¼Œéƒ¨åˆ†ç¤ºä¾‹è·³è¿‡")
        print("   å®‰è£…æ–¹æ³•: pip install safetensors")
    
    example_6_convert_existing()
    
    print("\n" + "="*60)
    print("âœ… æ‰€æœ‰ç¤ºä¾‹å®Œæˆ")
    print("="*60)
    print("\nè¯¦ç»†æ–‡æ¡£:")
    print("  - SafeTensorsä½¿ç”¨æŒ‡å—.md")
    print("  - SafeTensorså¿«é€Ÿå‚è€ƒ.txt")


if __name__ == "__main__":
    main()

