# å¿«é€Ÿå¼€å§‹

æœ¬æ–‡æ¡£å¸®åŠ©ä½ åœ¨ 5 åˆ†é’Ÿå†…ä¸Šæ‰‹ MiniMindã€‚

## ğŸ“‹ å‰ç½®è¦æ±‚

- Python 3.9+
- CUDA 11.8+ï¼ˆGPU è®­ç»ƒï¼‰
- 8GB+ æ˜¾å­˜ï¼ˆæ¨è 16GB+ï¼‰

## ğŸ”§ å®‰è£…

### 1. å…‹éš†é¡¹ç›®

```bash
git clone https://github.com/jingyaogong/minimind.git
cd minimind
```

### 2. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### 3. ä¸‹è½½é¢„è®­ç»ƒæƒé‡

ä» [ModelScope](https://modelscope.cn/models/gongjy/MiniMind-V1) æˆ– [HuggingFace](https://huggingface.co/jingyaogong/MiniMind-V1) ä¸‹è½½æƒé‡æ–‡ä»¶ï¼Œæ”¾å…¥ `out/` ç›®å½•ã€‚

## ğŸš€ å¿«é€Ÿä½“éªŒ

### å¯¹è¯æ¨ç†

```bash
# ä½¿ç”¨é»˜è®¤é…ç½®è¿›è¡Œå¯¹è¯
python scripts/eval_llm.py

# é€‰æ‹©æ¨¡å¼ï¼š
# [0] è‡ªåŠ¨æµ‹è¯• - ä½¿ç”¨é¢„è®¾é—®é¢˜æµ‹è¯•
# [1] æ‰‹åŠ¨è¾“å…¥ - è‡ªç”±å¯¹è¯
```

### æŸ¥çœ‹æ¨¡å‹ä¿¡æ¯

```python
from model.model_minimind import MiniMindConfig, MiniMindForCausalLM

# åˆ›å»ºé…ç½®
config = MiniMindConfig(hidden_size=512, num_hidden_layers=8)

# åˆ›å»ºæ¨¡å‹
model = MiniMindForCausalLM(config)

# æŸ¥çœ‹å‚æ•°é‡
print(f"å‚æ•°é‡: {sum(p.numel() for p in model.parameters()) / 1e6:.2f}M")
```

## ğŸ“Š æ¨¡å‹è§„æ ¼

| æ¨¡å‹ | hidden_size | num_layers | å‚æ•°é‡ | æ˜¾å­˜éœ€æ±‚ |
|------|-------------|------------|--------|----------|
| MiniMind-Small | 512 | 8 | 26M | ~2GB |
| MiniMind-Base | 768 | 16 | 104M | ~4GB |
| MiniMind-MoE | 640 | 8 | 145M | ~6GB |

## ğŸ¯ ä¸‹ä¸€æ­¥

- ğŸ“– é˜…è¯» [è®­ç»ƒæŒ‡å—](./è®­ç»ƒæŒ‡å—.md) äº†è§£å¦‚ä½•è®­ç»ƒæ¨¡å‹
- ğŸ”§ æŸ¥çœ‹ [å‘½ä»¤è¡Œå‚æ•°å¤§å…¨](./å‘½ä»¤è¡Œå‚æ•°å¤§å…¨.md) äº†è§£æ‰€æœ‰é…ç½®é€‰é¡¹
- ğŸ’¡ å‚è€ƒ [æ“ä½œç¤ºä¾‹](./æ“ä½œç¤ºä¾‹.md) è·å–æ›´å¤šä½¿ç”¨åœºæ™¯

## â“ å¸¸è§é—®é¢˜

### Q: æ˜¾å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ

A: å°è¯•ä»¥ä¸‹æ–¹æ³•ï¼š
1. å‡å° `batch_size`
2. ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯ `--accumulation_steps`
3. ä½¿ç”¨æ›´å°çš„æ¨¡å‹ `--hidden_size 512`

### Q: å¦‚ä½•ä½¿ç”¨ CPU è¿è¡Œï¼Ÿ

A: æ·»åŠ  `--device cpu` å‚æ•°ï¼š
```bash
python scripts/eval_llm.py --device cpu
```

### Q: å¦‚ä½•åŠ è½½è‡ªå·±è®­ç»ƒçš„æƒé‡ï¼Ÿ

A: æŒ‡å®šæƒé‡è·¯å¾„ï¼š
```bash
python scripts/eval_llm.py --weight my_model --save_dir ./my_weights